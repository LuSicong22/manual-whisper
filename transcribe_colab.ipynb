{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ğŸ™ï¸ å½•éŸ³è½¬å†™å·¥å…·\n",
                "\n",
                "**ä½¿ç”¨æ–¹æ³•**ï¼šç‚¹å‡»èœå•æ  **è¿è¡Œæ—¶ â†’ å…¨éƒ¨è¿è¡Œ**ï¼Œç­‰å¾…ä¸‹æ–¹å‡ºç°ä¸Šä¼ ç•Œé¢åï¼Œæ‹–å…¥å½•éŸ³æ–‡ä»¶å³å¯ã€‚\n",
                "\n",
                "> é¦–æ¬¡è¿è¡Œéœ€è¦å®‰è£…ä¾èµ–å’Œä¸‹è½½æ¨¡å‹ï¼Œå¤§çº¦éœ€è¦ 2-3 åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {
                "id": "install_deps"
            },
            "source": [
                "# ==================== ç¬¬ 1 æ­¥ï¼šå®‰è£…ä¾èµ–ï¼ˆè‡ªåŠ¨æ£€æŸ¥ï¼‰ ====================\n",
                "import os\n",
                "import sys\n",
                "import subprocess\n",
                "from importlib import metadata\n",
                "\n",
                "MARKER = '/content/.manual_whisper_env_v3'\n",
                "REQUIRED = {\n",
                "    'torch': '2.8.',\n",
                "    'torchvision': '0.23.',\n",
                "    'torchaudio': '2.8.',\n",
                "    'whisperx': '3.7.6',\n",
                "}\n",
                "\n",
                "\n",
                "def get_ver(pkg):\n",
                "    try:\n",
                "        return metadata.version(pkg)\n",
                "    except Exception:\n",
                "        return None\n",
                "\n",
                "\n",
                "def need_install():\n",
                "    if not os.path.exists(MARKER):\n",
                "        return True\n",
                "    for pkg, prefix in REQUIRED.items():\n",
                "        ver = get_ver(pkg)\n",
                "        if ver is None or not ver.startswith(prefix):\n",
                "            return True\n",
                "    return False\n",
                "\n",
                "\n",
                "def run(cmd):\n",
                "    print('>>>', cmd)\n",
                "    subprocess.check_call(cmd, shell=True)\n",
                "\n",
                "\n",
                "print('ğŸ“¦ æ£€æŸ¥è¿è¡Œç¯å¢ƒ...')\n",
                "if need_install():\n",
                "    print('âš™ï¸ æ£€æµ‹åˆ°é¦–æ¬¡è¿è¡Œæˆ–ç‰ˆæœ¬ä¸åŒ¹é…ï¼Œå¼€å§‹å®‰è£…å…¼å®¹ä¾èµ–ï¼ˆçº¦ 2-4 åˆ†é’Ÿï¼‰...')\n",
                "\n",
                "    run('pip install -U pip setuptools wheel')\n",
                "    run('pip uninstall -y torch torchvision torchaudio whisperx pyannote.audio pyannote.pipeline transformers huggingface-hub || true')\n",
                "    run('pip install --no-cache-dir \"numpy>=2.1,<2.3\" \"torch==2.8.0\" \"torchvision==0.23.0\" \"torchaudio==2.8.0\"')\n",
                "    run('pip install --no-cache-dir \"whisperx==3.7.6\" \"pyannote.audio==3.3.2\" \"transformers>=4.48,<4.57\" \"huggingface-hub<1.0\" \"gradio<6\"')\n",
                "\n",
                "    with open(MARKER, 'w', encoding='utf-8') as f:\n",
                "        f.write('ok')\n",
                "\n",
                "    print('âœ… ä¾èµ–å®‰è£…å®Œæˆã€‚è¯·ç‚¹å‡»èœå• Runtime -> Restart sessionï¼Œç„¶åå†æ¬¡ç‚¹å‡» Run allã€‚')\n",
                "    raise SystemExit('è¯·é‡å¯ä¼šè¯åç»§ç»­')\n",
                "else:\n",
                "    print('âœ… ä¾èµ–å·²å°±ç»ªï¼Œè·³è¿‡å®‰è£…ã€‚')\n",
                "    print('   torch      =', get_ver('torch'))\n",
                "    print('   torchvision=', get_ver('torchvision'))\n",
                "    print('   torchaudio =', get_ver('torchaudio'))\n",
                "    print('   whisperx   =', get_ver('whisperx'))\n",
                "\n",
                "\n"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "metadata": {
                "id": "transcribe_logic"
            },
            "source": [
                "# ==================== ç¬¬ 2 æ­¥ï¼šåŠ è½½è½¬å†™å¼•æ“ ====================\n",
                "import whisperx\n",
                "import gc\n",
                "import torch\n",
                "import json\n",
                "import re\n",
                "import time\n",
                "import os\n",
                "import traceback\n",
                "from datetime import timedelta\n",
                "\n",
                "# é…ç½®\n",
                "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "BATCH_SIZE = 16 if DEVICE == 'cuda' else 4\n",
                "COMPUTE_TYPE = 'float16' if DEVICE == 'cuda' else 'int8'\n",
                "MODEL_SIZE = 'large-v3'\n",
                "HF_TOKEN = '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'\n",
                "\n",
                "# å…¼å®¹ PyTorch 2.6+ é»˜è®¤ weights_only è¡Œä¸ºï¼Œé¿å…éƒ¨åˆ†æ¨¡å‹åŠ è½½å¤±è´¥\n",
                "try:\n",
                "    from omegaconf.listconfig import ListConfig\n",
                "    from omegaconf.dictconfig import DictConfig\n",
                "    torch.serialization.add_safe_globals([ListConfig, DictConfig])\n",
                "except Exception:\n",
                "    pass\n",
                "\n",
                "_original_torch_load = torch.load\n",
                "_original_serialization_load = torch.serialization.load\n",
                "\n",
                "def _safe_torch_load(*args, **kwargs):\n",
                "    kwargs['weights_only'] = False\n",
                "    return _original_torch_load(*args, **kwargs)\n",
                "\n",
                "def _safe_serialization_load(*args, **kwargs):\n",
                "    kwargs['weights_only'] = False\n",
                "    return _original_serialization_load(*args, **kwargs)\n",
                "\n",
                "torch.load = _safe_torch_load\n",
                "torch.serialization.load = _safe_serialization_load\n",
                "\n",
                "INITIAL_PROMPT = 'ä»¥ä¸‹æ˜¯ä¸€æ®µä¸­æ–‡ä¼šè®®å½•éŸ³çš„è½¬å†™ã€‚è¯·ä½¿ç”¨ç®€ä½“ä¸­æ–‡ã€‚'\n",
                "\n",
                "VAD_OPTIONS = {\n",
                "    'vad_onset': 0.5,\n",
                "    'vad_offset': 0.363,\n",
                "}\n",
                "\n",
                "\n",
                "def format_timestamp(seconds):\n",
                "    td = timedelta(seconds=seconds)\n",
                "    total_seconds = int(td.total_seconds())\n",
                "    hours = total_seconds // 3600\n",
                "    minutes = (total_seconds % 3600) // 60\n",
                "    secs = total_seconds % 60\n",
                "    return f'{hours:02d}:{minutes:02d}:{secs:02d}'\n",
                "\n",
                "\n",
                "def remove_hallucination_loops(text, max_repeat=3):\n",
                "    pattern = r'(.{2,20}?)\\1{' + str(max_repeat) + r',}'\n",
                "    return re.sub(pattern, r'\\1', text)\n",
                "\n",
                "\n",
                "def transcribe(audio_path):\n",
                "    \"\"\"è½¬å†™éŸ³é¢‘æ–‡ä»¶ï¼Œè¿”å› (markdownæ–‡æœ¬, mdæ–‡ä»¶è·¯å¾„, jsonæ–‡ä»¶è·¯å¾„)\"\"\"\n",
                "    start_time = time.time()\n",
                "\n",
                "    # åŠ è½½æ¨¡å‹\n",
                "    print(f'ğŸ“ åŠ è½½ Whisper {MODEL_SIZE} æ¨¡å‹ ({DEVICE})...')\n",
                "    model = whisperx.load_model(\n",
                "        MODEL_SIZE, DEVICE,\n",
                "        compute_type=COMPUTE_TYPE,\n",
                "        language='zh',\n",
                "        asr_options={'initial_prompt': INITIAL_PROMPT},\n",
                "        vad_options=VAD_OPTIONS,\n",
                "    )\n",
                "\n",
                "    # åŠ è½½éŸ³é¢‘\n",
                "    print('ğŸ”Š åŠ è½½éŸ³é¢‘...')\n",
                "    audio = whisperx.load_audio(audio_path)\n",
                "    audio_duration = len(audio) / 16000\n",
                "    print(f'   éŸ³é¢‘æ—¶é•¿: {audio_duration/60:.1f} åˆ†é’Ÿ')\n",
                "\n",
                "    # è½¬å†™\n",
                "    print('âœï¸ è½¬å†™ä¸­...')\n",
                "    result = model.transcribe(audio, batch_size=BATCH_SIZE, language='zh')\n",
                "\n",
                "    # å¯¹é½æ—¶é—´æˆ³ï¼ˆå¤±è´¥æ—¶å›é€€åˆ°åŸå§‹åˆ†æ®µæ—¶é—´æˆ³ï¼‰\n",
                "    print('ğŸ¯ å¯¹é½æ—¶é—´æˆ³...')\n",
                "    try:\n",
                "        model_a, metadata = whisperx.load_align_model(language_code='zh', device=DEVICE)\n",
                "        result = whisperx.align(result['segments'], model_a, metadata, audio, DEVICE, return_char_alignments=False)\n",
                "        del model_a; gc.collect()\n",
                "    except Exception as e:\n",
                "        print(f'âš ï¸ æ—¶é—´æˆ³å¯¹é½å¤±è´¥: {e}')\n",
                "        print('   ç»§ç»­ä½¿ç”¨åŸå§‹åˆ†æ®µæ—¶é—´æˆ³...')\n",
                "\n",
                "    # è¯´è¯äººåˆ†ç¦»\n",
                "    if HF_TOKEN:\n",
                "        print('ğŸ‘¥ è¯†åˆ«è¯´è¯äºº...')\n",
                "        try:\n",
                "            from whisperx.diarize import DiarizationPipeline\n",
                "            diarize_model = DiarizationPipeline(use_auth_token=HF_TOKEN, device=DEVICE)\n",
                "            diarize_segments = diarize_model(audio)\n",
                "            result = whisperx.assign_word_speakers(diarize_segments, result)\n",
                "        except Exception as e:\n",
                "            print(f'âš ï¸ è¯´è¯äººåˆ†ç¦»å¤±è´¥: {e}')\n",
                "\n",
                "    del model; gc.collect()\n",
                "    if DEVICE == 'cuda': torch.cuda.empty_cache()\n",
                "\n",
                "    # å¹»è§‰å»é‡\n",
                "    for seg in result.get('segments', []):\n",
                "        original = seg.get('text', '')\n",
                "        cleaned = remove_hallucination_loops(original)\n",
                "        if cleaned != original:\n",
                "            seg['text'] = cleaned\n",
                "\n",
                "    total_time = time.time() - start_time\n",
                "\n",
                "    # ç”Ÿæˆ Markdown\n",
                "    lines = []\n",
                "    lines.append(f'# ä¼šè®®å½•éŸ³è½¬å†™\\n\\n')\n",
                "    lines.append(f'**æºæ–‡ä»¶**: {os.path.basename(audio_path)}  \\n')\n",
                "    lines.append(f'**éŸ³é¢‘æ—¶é•¿**: {audio_duration/60:.1f} åˆ†é’Ÿ  \\n')\n",
                "    lines.append(f'**è½¬å†™è€—æ—¶**: {total_time:.0f} ç§’\\n\\n---\\n\\n')\n",
                "\n",
                "    current_speaker = None\n",
                "    for seg in result.get('segments', []):\n",
                "        text = seg.get('text', '').strip()\n",
                "        if not text: continue\n",
                "        start = seg.get('start', 0)\n",
                "        end = seg.get('end', 0)\n",
                "        speaker = seg.get('speaker', '')\n",
                "        ts = f'[{format_timestamp(start)} - {format_timestamp(end)}]'\n",
                "        if speaker and speaker != current_speaker:\n",
                "            lines.append(f'\\n### {speaker}\\n\\n')\n",
                "            current_speaker = speaker\n",
                "        lines.append(f'{ts} {text}\\n\\n')\n",
                "\n",
                "    md_text = ''.join(lines)\n",
                "\n",
                "    # ä¿å­˜æ–‡ä»¶\n",
                "    basename = os.path.splitext(os.path.basename(audio_path))[0]\n",
                "    md_path = f'/content/{basename}_transcript.md'\n",
                "    json_path = f'/content/{basename}_transcript.json'\n",
                "\n",
                "    with open(md_path, 'w', encoding='utf-8') as f:\n",
                "        f.write(md_text)\n",
                "    with open(json_path, 'w', encoding='utf-8') as f:\n",
                "        json.dump(result, f, ensure_ascii=False, indent=2)\n",
                "\n",
                "    print(f'\\nğŸ‰ è½¬å†™å®Œæˆï¼è€—æ—¶ {total_time:.0f} ç§’')\n",
                "    return md_text, md_path, json_path\n",
                "\n",
                "\n",
                "print(f'âœ… å¼•æ“åŠ è½½å®Œæˆï¼è®¾å¤‡: {DEVICE} | æ¨¡å‹: {MODEL_SIZE}')\n",
                "\n"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "metadata": {
                "id": "gradio_ui"
            },
            "source": [
                "# ==================== ç¬¬ 3 æ­¥ï¼šå¯åŠ¨ä¸Šä¼ ç•Œé¢ ====================\n",
                "import gradio as gr\n",
                "\n",
                "def process_audio(audio_file):\n",
                "    \"\"\"å¤„ç†ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶\"\"\"\n",
                "    if audio_file is None:\n",
                "        raise gr.Error('è¯·å…ˆä¸Šä¼ éŸ³é¢‘æ–‡ä»¶')\n",
                "\n",
                "    try:\n",
                "        md_text, md_path, json_path = transcribe(audio_file)\n",
                "        return md_text, md_path, json_path\n",
                "    except Exception as e:\n",
                "        traceback.print_exc()\n",
                "        raise gr.Error(f'è½¬å†™å¤±è´¥: {str(e)}')\n",
                "\n",
                "\n",
                "with gr.Blocks(title='ä¸­æ–‡ä¼šè®®å½•éŸ³è½¬å†™') as demo:\n",
                "    gr.Markdown('## ğŸ™ï¸ ä¸­æ–‡ä¼šè®®å½•éŸ³è½¬å†™å·¥å…·')\n",
                "    gr.Markdown('ä¸Šä¼ å½•éŸ³æ–‡ä»¶ï¼Œè‡ªåŠ¨è½¬å†™ä¸ºå¸¦æ—¶é—´æˆ³å’Œè¯´è¯äººæ ‡ç­¾çš„æ–‡å­—ç¨¿ã€‚')\n",
                "\n",
                "    with gr.Row():\n",
                "        audio_input = gr.File(\n",
                "            label='ğŸ“ ä¸Šä¼ å½•éŸ³æ–‡ä»¶ï¼ˆæ”¯æŒ m4a / mp3 / wav ç­‰ï¼‰',\n",
                "            file_types=['.m4a', '.mp3', '.wav', '.flac', '.ogg', '.wma', '.webm'],\n",
                "            type='filepath',\n",
                "        )\n",
                "\n",
                "    submit_btn = gr.Button('ğŸš€ å¼€å§‹è½¬å†™', variant='primary', size='lg')\n",
                "\n",
                "    gr.Markdown('### ğŸ“„ è½¬å†™ç»“æœ')\n",
                "    output_text = gr.Markdown(label='è½¬å†™å†…å®¹')\n",
                "\n",
                "    with gr.Row():\n",
                "        md_download = gr.File(label='ğŸ“¥ ä¸‹è½½ Markdown æ–‡ä»¶', interactive=False)\n",
                "        json_download = gr.File(label='ğŸ“¥ ä¸‹è½½ JSON æ–‡ä»¶', interactive=False)\n",
                "\n",
                "    submit_btn.click(\n",
                "        fn=process_audio,\n",
                "        inputs=[audio_input],\n",
                "        outputs=[output_text, md_download, json_download],\n",
                "    )\n",
                "\n",
                "ENABLE_PUBLIC_SHARE = False\n",
                "demo.launch(share=ENABLE_PUBLIC_SHARE, quiet=True)\n",
                "print('\\nğŸŒ ç•Œé¢å·²å¯åŠ¨ï¼é»˜è®¤ä¸åˆ›å»ºå…¬ç½‘é“¾æ¥ã€‚')"
            ],
            "execution_count": null,
            "outputs": []
        }
    ]
}