{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 🎙️ 中文会议录音转写工具\n",
                "\n",
                "**使用方法**：点击菜单栏 **运行时 → 全部运行**，等待下方出现上传界面后，拖入录音文件即可。\n",
                "\n",
                "> 首次运行需要安装依赖和下载模型，大约需要 2-3 分钟，请耐心等待。"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {
                "id": "install_deps"
            },
            "source": [
                "# ==================== 第 1 步：安装依赖 ====================\n",
                "print('📦 正在安装依赖... (请关注下方报错信息)')\n",
                "\n",
                "# 1. 升级 pip，避免依赖解析器过旧\n",
                "!pip install -U pip\n",
                "\n",
                "# 2. 安装 whisperx（带依赖解析）+ Gradio\n",
                "# 不再使用 numpy<2 + --no-deps 的组合，避免版本冲突和隐性缺包\n",
                "!pip install \"whisperx==3.7.6\" \"gradio<6\"\n",
                "\n",
                "print('✅ 依赖安装尝试完成！')\n",
                "try:\n",
                "    import numpy\n",
                "    import ctranslate2\n",
                "    import transformers\n",
                "    print(f'   Numpy: {numpy.__version__}')\n",
                "    print(f'   CTranslate2: {ctranslate2.__version__}')\n",
                "    print(f'   Transformers: {transformers.__version__}')\n",
                "except ImportError as e:\n",
                "    print(f'❌ 验证失败: {e}')"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "metadata": {
                "id": "transcribe_logic"
            },
            "source": [
                "# ==================== 第 2 步：加载转写引擎 ====================\n",
                "import whisperx\n",
                "import gc\n",
                "import torch\n",
                "import json\n",
                "import re\n",
                "import time\n",
                "import os\n",
                "import traceback\n",
                "from datetime import timedelta\n",
                "\n",
                "# 配置\n",
                "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "BATCH_SIZE = 16 if DEVICE == 'cuda' else 4\n",
                "COMPUTE_TYPE = 'float16' if DEVICE == 'cuda' else 'int8'\n",
                "MODEL_SIZE = 'large-v3'\n",
                "HF_TOKEN = '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'\n",
                "\n",
                "# 兼容 PyTorch 2.6+ 默认 weights_only 行为，避免部分模型加载失败\n",
                "_original_torch_load = torch.load\n",
                "def _safe_torch_load(*args, **kwargs):\n",
                "    kwargs.setdefault('weights_only', False)\n",
                "    return _original_torch_load(*args, **kwargs)\n",
                "torch.load = _safe_torch_load\n",
                "\n",
                "INITIAL_PROMPT = '以下是一段中文会议录音的转写。请使用简体中文。'\n",
                "\n",
                "VAD_OPTIONS = {\n",
                "    'vad_onset': 0.5,\n",
                "    'vad_offset': 0.363,\n",
                "}\n",
                "\n",
                "\n",
                "def format_timestamp(seconds):\n",
                "    td = timedelta(seconds=seconds)\n",
                "    total_seconds = int(td.total_seconds())\n",
                "    hours = total_seconds // 3600\n",
                "    minutes = (total_seconds % 3600) // 60\n",
                "    secs = total_seconds % 60\n",
                "    return f'{hours:02d}:{minutes:02d}:{secs:02d}'\n",
                "\n",
                "\n",
                "def remove_hallucination_loops(text, max_repeat=3):\n",
                "    pattern = r'(.{2,20}?)\\1{' + str(max_repeat) + r',}'\n",
                "    return re.sub(pattern, r'\\1', text)\n",
                "\n",
                "\n",
                "def transcribe(audio_path):\n",
                "    \"\"\"转写音频文件，返回 (markdown文本, md文件路径, json文件路径)\"\"\"\n",
                "    start_time = time.time()\n",
                "\n",
                "    # 加载模型\n",
                "    print(f'📝 加载 Whisper {MODEL_SIZE} 模型 ({DEVICE})...')\n",
                "    model = whisperx.load_model(\n",
                "        MODEL_SIZE, DEVICE,\n",
                "        compute_type=COMPUTE_TYPE,\n",
                "        language='zh',\n",
                "        asr_options={'initial_prompt': INITIAL_PROMPT},\n",
                "        vad_options=VAD_OPTIONS,\n",
                "    )\n",
                "\n",
                "    # 加载音频\n",
                "    print('🔊 加载音频...')\n",
                "    audio = whisperx.load_audio(audio_path)\n",
                "    audio_duration = len(audio) / 16000\n",
                "    print(f'   音频时长: {audio_duration/60:.1f} 分钟')\n",
                "\n",
                "    # 转写\n",
                "    print('✍️ 转写中...')\n",
                "    result = model.transcribe(audio, batch_size=BATCH_SIZE, language='zh')\n",
                "\n",
                "    # 对齐时间戳\n",
                "    print('🎯 对齐时间戳...')\n",
                "    model_a, metadata = whisperx.load_align_model(language_code='zh', device=DEVICE)\n",
                "    result = whisperx.align(result['segments'], model_a, metadata, audio, DEVICE, return_char_alignments=False)\n",
                "    del model_a; gc.collect()\n",
                "\n",
                "    # 说话人分离\n",
                "    if HF_TOKEN:\n",
                "        print('👥 识别说话人...')\n",
                "        try:\n",
                "            from whisperx.diarize import DiarizationPipeline\n",
                "            diarize_model = DiarizationPipeline(use_auth_token=HF_TOKEN, device=DEVICE)\n",
                "            diarize_segments = diarize_model(audio)\n",
                "            result = whisperx.assign_word_speakers(diarize_segments, result)\n",
                "        except Exception as e:\n",
                "            print(f'⚠️ 说话人分离失败: {e}')\n",
                "\n",
                "    del model; gc.collect()\n",
                "    if DEVICE == 'cuda': torch.cuda.empty_cache()\n",
                "\n",
                "    # 幻觉去重\n",
                "    for seg in result.get('segments', []):\n",
                "        original = seg.get('text', '')\n",
                "        cleaned = remove_hallucination_loops(original)\n",
                "        if cleaned != original:\n",
                "            seg['text'] = cleaned\n",
                "\n",
                "    total_time = time.time() - start_time\n",
                "\n",
                "    # 生成 Markdown\n",
                "    lines = []\n",
                "    lines.append(f'# 会议录音转写\\n\\n')\n",
                "    lines.append(f'**源文件**: {os.path.basename(audio_path)}  \\n')\n",
                "    lines.append(f'**音频时长**: {audio_duration/60:.1f} 分钟  \\n')\n",
                "    lines.append(f'**转写耗时**: {total_time:.0f} 秒\\n\\n---\\n\\n')\n",
                "\n",
                "    current_speaker = None\n",
                "    for seg in result.get('segments', []):\n",
                "        text = seg.get('text', '').strip()\n",
                "        if not text: continue\n",
                "        start = seg.get('start', 0)\n",
                "        end = seg.get('end', 0)\n",
                "        speaker = seg.get('speaker', '')\n",
                "        ts = f'[{format_timestamp(start)} - {format_timestamp(end)}]'\n",
                "        if speaker and speaker != current_speaker:\n",
                "            lines.append(f'\\n### {speaker}\\n\\n')\n",
                "            current_speaker = speaker\n",
                "        lines.append(f'{ts} {text}\\n\\n')\n",
                "\n",
                "    md_text = ''.join(lines)\n",
                "\n",
                "    # 保存文件\n",
                "    basename = os.path.splitext(os.path.basename(audio_path))[0]\n",
                "    md_path = f'/content/{basename}_transcript.md'\n",
                "    json_path = f'/content/{basename}_transcript.json'\n",
                "\n",
                "    with open(md_path, 'w', encoding='utf-8') as f:\n",
                "        f.write(md_text)\n",
                "    with open(json_path, 'w', encoding='utf-8') as f:\n",
                "        json.dump(result, f, ensure_ascii=False, indent=2)\n",
                "\n",
                "    print(f'\\n🎉 转写完成！耗时 {total_time:.0f} 秒')\n",
                "    return md_text, md_path, json_path\n",
                "\n",
                "\n",
                "print(f'✅ 引擎加载完成！设备: {DEVICE} | 模型: {MODEL_SIZE}')"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "metadata": {
                "id": "gradio_ui"
            },
            "source": [
                "# ==================== 第 3 步：启动上传界面 ====================\n",
                "import gradio as gr\n",
                "\n",
                "def process_audio(audio_file):\n",
                "    \"\"\"处理上传的音频文件\"\"\"\n",
                "    if audio_file is None:\n",
                "        raise gr.Error('请先上传音频文件')\n",
                "\n",
                "    try:\n",
                "        md_text, md_path, json_path = transcribe(audio_file)\n",
                "        return md_text, md_path, json_path\n",
                "    except Exception as e:\n",
                "        traceback.print_exc()\n",
                "        raise gr.Error(f'转写失败: {str(e)}')\n",
                "\n",
                "\n",
                "with gr.Blocks(title='中文会议录音转写') as demo:\n",
                "    gr.Markdown('## 🎙️ 中文会议录音转写工具')\n",
                "    gr.Markdown('上传录音文件，自动转写为带时间戳和说话人标签的文字稿。')\n",
                "\n",
                "    with gr.Row():\n",
                "        audio_input = gr.File(\n",
                "            label='📁 上传录音文件（支持 m4a / mp3 / wav 等）',\n",
                "            file_types=['.m4a', '.mp3', '.wav', '.flac', '.ogg', '.wma', '.webm'],\n",
                "            type='filepath',\n",
                "        )\n",
                "\n",
                "    submit_btn = gr.Button('🚀 开始转写', variant='primary', size='lg')\n",
                "\n",
                "    gr.Markdown('### 📄 转写结果')\n",
                "    output_text = gr.Markdown(label='转写内容')\n",
                "\n",
                "    with gr.Row():\n",
                "        md_download = gr.File(label='📥 下载 Markdown 文件', interactive=False)\n",
                "        json_download = gr.File(label='📥 下载 JSON 文件', interactive=False)\n",
                "\n",
                "    submit_btn.click(\n",
                "        fn=process_audio,\n",
                "        inputs=[audio_input],\n",
                "        outputs=[output_text, md_download, json_download],\n",
                "    )\n",
                "\n",
                "ENABLE_PUBLIC_SHARE = False\n",
                "demo.launch(share=ENABLE_PUBLIC_SHARE, quiet=True)\n",
                "print('\\n🌐 界面已启动！默认不创建公网链接。')"
            ],
            "execution_count": null,
            "outputs": []
        }
    ]
}
